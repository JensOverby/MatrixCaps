{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data1 = torch.tensor([[[[-0.5450, -0.5450],\n",
    "          [-0.5450, -0.5450]],\n",
    "\n",
    "         [[-0.1665, -0.1665],\n",
    "          [-0.1665, -0.1665]],\n",
    "\n",
    "         [[-0.2075, -0.2075],\n",
    "          [-0.2075, -0.2075]],\n",
    "\n",
    "         [[ 0.2935,  0.2935],\n",
    "          [ 0.2935,  0.2935]],\n",
    "\n",
    "         [[ 0.8966,  0.8966],\n",
    "          [ 0.8966,  0.8966]],\n",
    "\n",
    "         [[-0.6388, -0.6388],\n",
    "          [-0.6388, -0.6388]],\n",
    "\n",
    "         [[-0.5887, -0.5887],\n",
    "          [-0.5887, -0.5887]],\n",
    "\n",
    "         [[-0.1282, -0.1282],\n",
    "          [-0.1282, -0.1282]],\n",
    "\n",
    "         [[ 0.6620,  0.6620],\n",
    "          [ 0.6620,  0.6620]],\n",
    "\n",
    "         [[-0.5807, -0.5807],\n",
    "          [-0.5807, -0.5807]],\n",
    "\n",
    "         [[-0.6910, -0.6910],\n",
    "          [-0.6910, -0.6910]],\n",
    "\n",
    "         [[-0.3250, -0.3250],\n",
    "          [-0.3250, -0.3250]],\n",
    "\n",
    "         [[ 0.2326,  0.2326],\n",
    "          [ 0.2326,  0.2326]],\n",
    "\n",
    "         [[ 0.4437,  0.4437],\n",
    "          [ 0.4437,  0.4437]],\n",
    "\n",
    "         [[ 0.0993,  0.0993],\n",
    "          [ 0.0993,  0.0993]],\n",
    "\n",
    "         [[ 0.6403,  0.6403],\n",
    "          [ 0.6403,  0.6403]],\n",
    "\n",
    "         [[ 0.3727,  0.3727],\n",
    "          [ 0.3727,  0.3727]],\n",
    "\n",
    "         [[ 0.6524,  0.6524],\n",
    "          [ 0.6524,  0.6524]],\n",
    "\n",
    "         [[ 0.2030,  0.2030],\n",
    "          [ 0.2030,  0.2030]],\n",
    "\n",
    "         [[-0.5824, -0.5824],\n",
    "          [-0.5824, -0.5824]],\n",
    "\n",
    "         [[ 0.3297,  0.3297],\n",
    "          [ 0.3297,  0.3297]],\n",
    "\n",
    "         [[ 0.7594,  0.7594],\n",
    "          [ 0.7594,  0.7594]],\n",
    "\n",
    "         [[-0.0608, -0.0608],\n",
    "          [-0.0608, -0.0608]],\n",
    "\n",
    "         [[ 0.8649,  0.8649],\n",
    "          [ 0.8649,  0.8649]],\n",
    "\n",
    "         [[-0.1188, -0.1188],\n",
    "          [-0.1188, -0.1188]],\n",
    "\n",
    "         [[ 0.5525,  0.5525],\n",
    "          [ 0.5525,  0.5525]],\n",
    "\n",
    "         [[ 0.0882,  0.0882],\n",
    "          [ 0.0882,  0.0882]],\n",
    "\n",
    "         [[-0.2268, -0.2268],\n",
    "          [-0.2268, -0.2268]],\n",
    "\n",
    "         [[ 0.2873,  0.2873],\n",
    "          [ 0.2873,  0.2873]],\n",
    "\n",
    "         [[ 0.1671,  0.1671],\n",
    "          [ 0.1671,  0.1671]],\n",
    "\n",
    "         [[-0.8462, -0.8462],\n",
    "          [-0.8462, -0.8462]],\n",
    "\n",
    "         [[ 0.5427,  0.5427],\n",
    "          [ 0.5427,  0.5427]],\n",
    "\n",
    "         [[ 0.6956,  0.6956],\n",
    "          [ 0.6956,  0.6956]],\n",
    "\n",
    "         [[-0.3219, -0.3219],\n",
    "          [-0.3219, -0.3219]],\n",
    "\n",
    "         [[-0.1133, -0.1133],\n",
    "          [-0.1133, -0.1133]],\n",
    "\n",
    "         [[ 0.3137,  0.3137],\n",
    "          [ 0.3137,  0.3137]],\n",
    "\n",
    "         [[-0.6801, -0.6801],\n",
    "          [-0.6801, -0.6801]],\n",
    "\n",
    "         [[-0.4386, -0.4386],\n",
    "          [-0.4386, -0.4386]],\n",
    "\n",
    "         [[-0.5029, -0.5029],\n",
    "          [-0.5029, -0.5029]],\n",
    "\n",
    "         [[ 0.3319,  0.3319],\n",
    "          [ 0.3319,  0.3319]],\n",
    "\n",
    "         [[-0.5069, -0.5069],\n",
    "          [-0.5069, -0.5069]],\n",
    "\n",
    "         [[-0.8566, -0.8566],\n",
    "          [-0.8566, -0.8566]],\n",
    "\n",
    "         [[-0.2228, -0.2228],\n",
    "          [-0.2228, -0.2228]],\n",
    "\n",
    "         [[-0.8778, -0.8778],\n",
    "          [-0.8778, -0.8778]],\n",
    "\n",
    "         [[ 0.1914,  0.1914],\n",
    "          [ 0.1914,  0.1914]],\n",
    "\n",
    "         [[-0.3679, -0.3679],\n",
    "          [-0.3679, -0.3679]],\n",
    "\n",
    "         [[-0.7181, -0.7181],\n",
    "          [-0.7181, -0.7181]],\n",
    "\n",
    "         [[-0.3126, -0.3126],\n",
    "          [-0.3126, -0.3126]]]])\n",
    "\n",
    "data2 = torch.tensor([[[[ 0.6363,  0.6363],\n",
    "          [ 0.6363,  0.6363]],\n",
    "\n",
    "         [[ 0.6825,  0.6825],\n",
    "          [ 0.6825,  0.6825]],\n",
    "\n",
    "         [[ 0.7041,  0.7041],\n",
    "          [ 0.7041,  0.7041]]]])\n",
    "\n",
    "class args():\n",
    "    batch_size = 1\n",
    "    routing = \"EM_routing\"\n",
    "\n",
    "lambda_ = 2e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphics(new_mus, new_sigs, data):\n",
    "    df = (pd.DataFrame(index=[1, 2]).assign(mus = new_mus).assign(sigs = new_sigs))\n",
    "\n",
    "    xx = np.linspace(0, 100, 100)\n",
    "    yy = scs.multivariate_normal.pdf(xx, mean=new_mus[0], cov=new_sigs[0])\n",
    "\n",
    "    colors = sns.color_palette('Dark2', 3)\n",
    "    fig, ax = plt.subplots(figsize=(9, 7))\n",
    "    ax.set_ylim(-0.001, np.max(yy))\n",
    "    ax.plot(xx, yy, color=colors[1])\n",
    "    ax.axvline(new_mus[0], ymin=0., color=colors[1])\n",
    "    ax.fill_between(xx, 0, yy, alpha=0.5, color=colors[1])\n",
    "    lo, hi = ax.get_ylim()\n",
    "    ax.annotate(f'$\\mu_1$: {new_mus[0]:3.2f}', \n",
    "                fontsize=12, fontweight='demi',\n",
    "                xy=(new_mus[0], (hi-lo) / 2), \n",
    "                xycoords='data', xytext=(80, (hi-lo) / 2),\n",
    "                arrowprops=dict(facecolor='black', connectionstyle=\"arc3,rad=0.2\",shrink=0.05))\n",
    "    ax.fill_between(xx, 0, yy, alpha=0.5, color=colors[2])\n",
    "\n",
    "    dot_kwds = dict(markerfacecolor='white', markeredgecolor='black', markeredgewidth=1, markersize=10)\n",
    "    ax.plot(height, len(height)*[0], 'o', **dot_kwds)\n",
    "    ax.set_ylim(-0.001, np.max(yy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.distributions import Normal\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import torchnet as tnt\n",
    "from torchnet.logger import VisdomPlotLogger, VisdomLogger\n",
    "from torchnet.engine import Engine\n",
    "\n",
    "torch.manual_seed(1991)\n",
    "random.seed(1991)\n",
    "np.random.seed(1991)\n",
    "\n",
    "\n",
    "class ConvCaps(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Capsule Layer.\n",
    "    Args:\n",
    "        B:input number of types of capsules.\n",
    "        C:output number of types of capsules.\n",
    "        kernel: kernel of convolution. kernel=0 means the capsules in layer L+1's\n",
    "        receptive field contain all capsules in layer L. Kernel=0 is used in the\n",
    "        final ClassCaps layer.\n",
    "        stride:stride of convolution\n",
    "        iteration: number of EM iterations\n",
    "        coordinate_add: whether to use Coordinate Addition\n",
    "        transform_share: whether to share transformation matrix.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, B=32, C=32, kernel=3, stride=2, iteration=3,\n",
    "                 coordinate_add=False, transform_share=False):\n",
    "        super(ConvCaps, self).__init__()\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.K = kernel  # kernel = 0 means full receptive field like class capsules\n",
    "        self.Bkk = None\n",
    "        self.Cww = None\n",
    "        self.b = args.batch_size\n",
    "        self.stride = stride\n",
    "        self.coordinate_add = coordinate_add\n",
    "        self.transform_share = transform_share\n",
    "        self.beta_v = None\n",
    "        self.beta_a = None\n",
    "        if not transform_share:\n",
    "            self.W = nn.Parameter(torch.randn(B, kernel, kernel, C,\n",
    "                                              4, 4))  # B,K,K,C,4,4\n",
    "        else:\n",
    "            self.W = nn.Parameter(torch.randn(B, C, 4, 4))  # B,C,4,4\n",
    "\n",
    "        self.iteration = iteration\n",
    "\n",
    "    def coordinate_addition(self, width_in, votes):\n",
    "        add = [[i / width_in, j / width_in] for i in range(width_in) for j in range(width_in)]  # K,K,w,w\n",
    "        add = Variable(torch.Tensor(add)).view(1, 1, self.K, self.K, 1, 1, 1, 2)\n",
    "        add = add.expand(self.b, self.B, self.K, self.K, self.C, 1, 1, 2).contiguous()\n",
    "        votes[:, :, :, :, :, :, :, :2, -1] = votes[:, :, :, :, :, :, :, :2, -1] + add\n",
    "        return votes\n",
    "\n",
    "    def down_w(self, w):\n",
    "        return range(w * self.stride, w * self.stride + self.K)\n",
    "\n",
    "    def EM_routing(self, lambda_, a_, V):\n",
    "        # routing coefficient\n",
    "        R = Variable(torch.ones([self.b, self.Bkk, self.Cww]), requires_grad=False) / self.Cww\n",
    "\n",
    "        for i in range(self.iteration):\n",
    "            # M-step\n",
    "            R = (R * a_)[..., None]\n",
    "            sum_R = R.sum(1)\n",
    "            mu = ((R * V).sum(1) / sum_R)[:, None, :, :]\n",
    "            sigma_square = (R * (V - mu) ** 2).sum(1) / sum_R\n",
    "\n",
    "            # E-step\n",
    "            if i != self.iteration - 1:\n",
    "                mu, sigma_square, V_, a__ = mu.data, sigma_square.data, V.data, a_.data\n",
    "                normal = Normal(mu, sigma_square[:, None, :, :] ** (1 / 2))\n",
    "                p = torch.exp(normal.log_prob(V_))\n",
    "                ap = a__ * p.sum(-1)\n",
    "                R = Variable(ap / torch.sum(ap, -1)[..., None], requires_grad=False)\n",
    "            else:\n",
    "                const = (self.beta_v.expand_as(sigma_square) + torch.log(sigma_square)) * sum_R\n",
    "                a = torch.sigmoid(lambda_ * (self.beta_a.repeat(self.b, 1) - const.sum(2)))\n",
    "\n",
    "        return a, mu\n",
    "\n",
    "    #torch.save(poses, 'poses.pt')\n",
    "\n",
    "    def forward(self, x, lambda_):\n",
    "        poses, activations = x\n",
    "        width_in = poses.size(2)\n",
    "        w = int((width_in - self.K) / self.stride + 1) if self.K else 1  # 5\n",
    "        self.Cww = w * w * self.C\n",
    "        self.b = poses.size(0)\n",
    "\n",
    "        if self.beta_v is None:\n",
    "            self.beta_v = nn.Parameter(torch.randn(1, self.Cww, 1))\n",
    "            self.beta_a = nn.Parameter(torch.randn(1, self.Cww))\n",
    "\n",
    "        if self.transform_share:\n",
    "            if self.K == 0:\n",
    "                self.K = width_in  # class Capsules' kernel = width_in\n",
    "            W = self.W.view(self.B, 1, 1, self.C, 4, 4).expand(self.B, self.K, self.K, self.C, 4, 4).contiguous()\n",
    "        else:\n",
    "            W = self.W  # B,K,K,C,4,4\n",
    "\n",
    "        self.Bkk = self.K * self.K * self.B\n",
    "\n",
    "        # used to store every capsule i's poses in each capsule c's receptive field\n",
    "        pose = poses.contiguous()  # b,16*32,12,12\n",
    "        pose = pose.view(self.b, 16, self.B, width_in, width_in).permute(0, 2, 3, 4, 1).contiguous()  # b,B,12,12,16\n",
    "        poses = torch.stack([pose[:, :, self.stride * i:self.stride * i + self.K,\n",
    "                             self.stride * j:self.stride * j + self.K, :] for i in range(w) for j in range(w)],\n",
    "                            dim=-1)  # b,B,K,K,w*w,16\n",
    "        poses = poses.view(self.b, self.B, self.K, self.K, 1, w, w, 4, 4)  # b,B,K,K,1,w,w,4,4\n",
    "        W_hat = W[None, :, :, :, :, None, None, :, :]  # 1,B,K,K,C,1,1,4,4\n",
    "        votes = W_hat @ poses  # b,B,K,K,C,w,w,4,4\n",
    "\n",
    "        if self.coordinate_add:\n",
    "            votes = self.coordinate_addition(width_in, votes)\n",
    "            activation = activations.view(self.b, -1)[..., None].repeat(1, 1, self.Cww)\n",
    "        else:\n",
    "            activations_ = [activations[:, :, self.down_w(x), :][:, :, :, self.down_w(y)]\n",
    "                            for x in range(w) for y in range(w)]\n",
    "            activation = torch.stack(\n",
    "                activations_, dim=4).view(self.b, self.Bkk, 1, -1) \\\n",
    "                .repeat(1, 1, self.C, 1).view(self.b, self.Bkk, self.Cww)\n",
    "\n",
    "        votes = votes.view(self.b, self.Bkk, self.Cww, 16)\n",
    "        activations, poses = getattr(self, args.routing)(lambda_, activation, votes)\n",
    "        return poses.view(self.b, self.C, w, w, -1), activations.view(self.b, self.C, w, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "convcaps1 = ConvCaps(3, 1, kernel=1, stride=1, iteration=3, coordinate_add=False, transform_share=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = data1, data2\n",
    "output = convcaps1.forward(x, lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# This is a Title"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "# Another"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown('# This is a Title'))\n",
    "kaj = [1,2,3]\n",
    "display(Markdown('# Another'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
